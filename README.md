# Toxic-Comment-Classifier
In this project, a web application is built to allow user to upload a csv file with comments or directly type in a comment to obtain the percentage for each toxic categories which are toxic, severe toxic, obscene, threat, insult and identity hate.
